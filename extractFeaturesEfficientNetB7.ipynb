{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/4c/6a/c7752603060d076dfed95135b78b047dc71792630cbcb022e3693d6f32ef/torchvision-0.21.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.21.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.6.0->torchvision) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.6.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.6.0->torchvision) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.6.0->torchvision) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.5)\n",
      "Using cached torchvision-0.21.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scenedetect[opencv]\n",
      "  Obtaining dependency information for scenedetect[opencv] from https://files.pythonhosted.org/packages/b1/5b/c090fe55521265eb1816c303267e985125000a4e32237e95562ed462608f/scenedetect-0.6.6-py3-none-any.whl.metadata\n",
      "  Downloading scenedetect-0.6.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting Click (from scenedetect[opencv])\n",
      "  Obtaining dependency information for Click from https://files.pythonhosted.org/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scenedetect[opencv]) (1.26.4)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scenedetect[opencv]) (4.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scenedetect[opencv]) (4.67.1)\n",
      "Collecting opencv-python (from scenedetect[opencv])\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/a4/7d/f1c30a92854540bf789e9cd5dde7ef49bbe63f855b85a2e6b3db8135c591/opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Click->scenedetect[opencv]) (0.4.6)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "   ---------------------------------------- 0.0/98.2 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 30.7/98.2 kB 435.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 98.2/98.2 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/39.5 MB 2.4 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 0.2/39.5 MB 2.3 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 0.3/39.5 MB 2.1 MB/s eta 0:00:19\n",
      "    --------------------------------------- 0.5/39.5 MB 2.9 MB/s eta 0:00:14\n",
      "    --------------------------------------- 0.7/39.5 MB 3.0 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.8/39.5 MB 2.9 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 1.0/39.5 MB 3.1 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 1.2/39.5 MB 3.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.5/39.5 MB 3.5 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.7/39.5 MB 3.5 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.9/39.5 MB 3.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 2.1/39.5 MB 3.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 2.1/39.5 MB 3.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 2.2/39.5 MB 3.5 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 2.2/39.5 MB 3.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.4/39.5 MB 3.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.4/39.5 MB 3.0 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 2.5/39.5 MB 3.0 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 2.7/39.5 MB 3.1 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.9/39.5 MB 3.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.2/39.5 MB 3.2 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 3.4/39.5 MB 3.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 3.6/39.5 MB 3.4 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 3.9/39.5 MB 3.5 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.1/39.5 MB 3.5 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.3/39.5 MB 3.6 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 4.6/39.5 MB 3.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 4.7/39.5 MB 3.6 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 4.9/39.5 MB 3.6 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.0/39.5 MB 3.6 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.1/39.5 MB 3.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.2/39.5 MB 3.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.5/39.5 MB 3.6 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.6/39.5 MB 3.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.7/39.5 MB 3.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.8/39.5 MB 3.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 5.8/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.0/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.0/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.3/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.5/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.6/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 6.8/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.0/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.2/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.5/39.5 MB 3.5 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 7.7/39.5 MB 3.5 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 8.0/39.5 MB 3.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.2/39.5 MB 3.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.3/39.5 MB 3.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.4/39.5 MB 3.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.5/39.5 MB 3.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.5/39.5 MB 3.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 8.6/39.5 MB 3.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 8.8/39.5 MB 3.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 9.1/39.5 MB 3.5 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 9.3/39.5 MB 3.5 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 9.7/39.5 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 9.9/39.5 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.2/39.5 MB 3.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 10.4/39.5 MB 3.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 10.7/39.5 MB 3.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 10.9/39.5 MB 3.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 11.2/39.5 MB 3.9 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 11.5/39.5 MB 3.9 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 11.7/39.5 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 12.0/39.5 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 12.3/39.5 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.5/39.5 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.6/39.5 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.8/39.5 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 13.0/39.5 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 13.3/39.5 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 13.6/39.5 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 13.8/39.5 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 14.1/39.5 MB 4.3 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 14.2/39.5 MB 4.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 14.5/39.5 MB 4.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 14.9/39.5 MB 4.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 15.1/39.5 MB 4.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 15.3/39.5 MB 4.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 15.6/39.5 MB 4.5 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 15.9/39.5 MB 4.6 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 16.2/39.5 MB 4.9 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 16.5/39.5 MB 4.9 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 16.8/39.5 MB 5.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 17.2/39.5 MB 5.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 17.5/39.5 MB 5.1 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 17.8/39.5 MB 5.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.1/39.5 MB 5.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 18.5/39.5 MB 5.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.7/39.5 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 19.0/39.5 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 19.3/39.5 MB 5.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 19.6/39.5 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 19.8/39.5 MB 5.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 20.1/39.5 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 20.5/39.5 MB 5.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 20.8/39.5 MB 5.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 21.1/39.5 MB 6.0 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 21.5/39.5 MB 6.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 21.8/39.5 MB 6.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 22.1/39.5 MB 6.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 22.5/39.5 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.8/39.5 MB 6.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 23.1/39.5 MB 6.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 23.4/39.5 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 23.8/39.5 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.0/39.5 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.3/39.5 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.6/39.5 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 24.9/39.5 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 25.1/39.5 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 25.4/39.5 MB 6.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.7/39.5 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 25.9/39.5 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 26.1/39.5 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 26.4/39.5 MB 6.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 26.8/39.5 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.0/39.5 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.4/39.5 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.5/39.5 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 27.8/39.5 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.0/39.5 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.1/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.3/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.6/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 28.9/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 29.3/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 29.4/39.5 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.7/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 30.0/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 30.3/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 30.6/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.9/39.5 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 31.3/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.7/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 32.0/39.5 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 32.2/39.5 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 32.5/39.5 MB 6.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.8/39.5 MB 6.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 33.1/39.5 MB 6.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 33.5/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/39.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.0/39.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 34.3/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.6/39.5 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.7/39.5 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.7/39.5 MB 1.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.8/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.8/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.8/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.8/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.8/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.8/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 34.9/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 35.0/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 35.1/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 35.4/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 35.6/39.5 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 35.8/39.5 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 36.2/39.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 36.5/39.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 36.7/39.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 36.8/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 36.9/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 37.1/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 37.2/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 37.2/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 37.3/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 37.5/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 37.6/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 37.6/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 37.7/39.5 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 37.9/39.5 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.9/39.5 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.1/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.1/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.1/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.1/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.1/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.2/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.7/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.0/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.2/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.4/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading scenedetect-0.6.6-py3-none-any.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.6/131.6 kB 7.6 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python, Click, scenedetect\n",
      "Successfully installed Click-8.1.8 opencv-python-4.11.0.86 scenedetect-0.6.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scenedetect[opencv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch and torchvision imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Scenedetect and config imports remain unchanged\n",
    "from scenedetect import VideoManager, SceneManager, StatsManager\n",
    "from scenedetect.detectors import ContentDetector\n",
    "from scenedetect.scene_manager import save_images, write_scene_list_html\n",
    "import config\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------\n",
    "# # Set up directories based on current working directory\n",
    "# # ------------------------------\n",
    "# base_dir = os.path.join(os.getcwd(), \"features\")  # base directory for your data\n",
    "# video_dir = os.path.join(base_dir, \"videos_train\")        # Directory containing input videos\n",
    "# feat_dir = os.path.join(base_dir, \"feat_train\")        # Directory to save feature .npy files\n",
    "# temp_dir = os.path.join(base_dir, \"temporary_images\") # Temporary folder for frame extraction\n",
    "# scenes_dir = os.path.join(base_dir, \"scenes\")         # Directory to save scene images\n",
    "\n",
    "# # Create necessary directories if they don't exist\n",
    "# os.makedirs(feat_dir, exist_ok=True)\n",
    "# os.makedirs(scenes_dir, exist_ok=True)\n",
    "\n",
    "# # ------------------------------\n",
    "# # Set device (CPU if no CUDA available)\n",
    "# # ------------------------------\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Using device:\", device)\n",
    "\n",
    "# # ------------------------------\n",
    "# # Define the PyTorch Model Wrapper for EfficientNetB7\n",
    "# # ------------------------------\n",
    "# class EfficientNetB7_Features(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Wraps torchvision's EfficientNetB7 to output features from the penultimate layer.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, base_model):\n",
    "#         super(EfficientNetB7_Features, self).__init__()\n",
    "#         self.features = base_model.features\n",
    "#         self.avgpool = base_model.avgpool\n",
    "#         self.dropout = base_model.classifier[0]  # keep the dropout output\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = self.avgpool(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.dropout(x)\n",
    "#         return x\n",
    "\n",
    "# def model_cnn_load():\n",
    "#     \"\"\"\n",
    "#     Loads a pretrained EfficientNetB7 model from torchvision,\n",
    "#     wraps it to output feature vectors, and moves it to the appropriate device.\n",
    "#     \"\"\"\n",
    "#     base_model = models.efficientnet_b7(pretrained=True)\n",
    "#     model_final = EfficientNetB7_Features(base_model)\n",
    "#     model_final.to(device)\n",
    "#     print(\"Model loaded:\")\n",
    "#     print(model_final)\n",
    "#     return model_final\n",
    "\n",
    "# # ------------------------------\n",
    "# # Define image transformation pipeline\n",
    "# # ------------------------------\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((600, 600)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                          std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "# def load_image(path):\n",
    "#     \"\"\"\n",
    "#     Loads an image using PIL and applies the transformation.\n",
    "#     \"\"\"\n",
    "#     img = Image.open(path).convert('RGB')\n",
    "#     return transform(img)\n",
    "\n",
    "# # ------------------------------\n",
    "# # Frame extraction from video segments\n",
    "# # ------------------------------\n",
    "# def video_to_frames(video, startT, stopT, video_directory, tmp_dir):\n",
    "#     \"\"\"\n",
    "#     Extracts frames from a video between startT and stopT (in seconds).\n",
    "    \n",
    "#     Parameters:\n",
    "#       video         : Video filename (e.g., 'sample.avi')\n",
    "#       startT, stopT : Start and stop times (in seconds) for extraction.\n",
    "#       video_directory: Directory where video files are stored.\n",
    "#       tmp_dir       : Temporary directory to store extracted frames.\n",
    "      \n",
    "#     Returns:\n",
    "#       List of file paths to the extracted frames.\n",
    "#     \"\"\"\n",
    "#     startT_ms = startT * 1000\n",
    "#     stopT_ms = stopT * 1000\n",
    "\n",
    "#     if os.path.exists(tmp_dir):\n",
    "#         shutil.rmtree(tmp_dir)\n",
    "#     os.makedirs(tmp_dir)\n",
    "    \n",
    "#     video_path = os.path.join(video_directory, video)\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     count = 0\n",
    "#     image_list = []\n",
    "#     success = True\n",
    "    \n",
    "#     # Skip frames until reaching startT\n",
    "#     while success and cap.get(cv2.CAP_PROP_POS_MSEC) < startT_ms:\n",
    "#         success, _ = cap.read()\n",
    "    \n",
    "#     # Extract frames until stopT is reached\n",
    "#     while success and cap.get(cv2.CAP_PROP_POS_MSEC) <= stopT_ms:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         frame_path = os.path.join(tmp_dir, f'frame{count}.jpg')\n",
    "#         cv2.imwrite(frame_path, frame)\n",
    "#         image_list.append(frame_path)\n",
    "#         count += 1\n",
    "        \n",
    "#     cap.release()\n",
    "#     print(f\"Extracted {len(image_list)} frames from {video}\")\n",
    "#     return image_list\n",
    "\n",
    "# # ------------------------------\n",
    "# # Feature extraction for a video scene\n",
    "# # ------------------------------\n",
    "# def extract_features(video, model, startT, stopT, video_directory, tmp_dir):\n",
    "#     \"\"\"\n",
    "#     Extracts features for a video scene defined by startT and stopT.\n",
    "#     Uniformly samples 20 frames, processes them, and passes them through the CNN model.\n",
    "    \n",
    "#     Returns a NumPy array containing the extracted features.\n",
    "#     \"\"\"\n",
    "#     image_list = video_to_frames(video, startT, stopT, video_directory, tmp_dir)\n",
    "#     if len(image_list) == 0:\n",
    "#         print(\"No frames extracted!\")\n",
    "#         return None\n",
    "#     samples = np.round(np.linspace(0, len(image_list) - 1, 20)).astype(int)\n",
    "#     sampled_images = [image_list[i] for i in samples]\n",
    "    \n",
    "#     images = [load_image(p) for p in sampled_images]\n",
    "#     images = torch.stack(images).to(device)\n",
    "    \n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         features = model(images)\n",
    "#     features = features.cpu().numpy()\n",
    "    \n",
    "#     # Clean up temporary directory\n",
    "#     shutil.rmtree(tmp_dir)\n",
    "#     return features\n",
    "\n",
    "# # ------------------------------\n",
    "# # Scene detection using scenedetect\n",
    "# # ------------------------------\n",
    "# def proposal_module(video, video_directory):\n",
    "#     \"\"\"\n",
    "#     Detects scenes in a video using scenedetect.\n",
    "#     Saves representative scene images in the 'scenes' directory and an HTML summary.\n",
    "    \n",
    "#     Returns:\n",
    "#       A list of timestamps (in seconds). For each scene, two values are appended: start and end.\n",
    "#     \"\"\"\n",
    "#     video_path = os.path.join(video_directory, video)\n",
    "#     stats_path = os.path.join(os.getcwd(), \"result.csv\")\n",
    "    \n",
    "#     video_manager = VideoManager([video_path])\n",
    "#     stats_manager = StatsManager()\n",
    "#     scene_manager = SceneManager(stats_manager)\n",
    "    \n",
    "#     scene_manager.add_detector(ContentDetector(threshold=30))\n",
    "#     video_manager.set_downscale_factor()\n",
    "    \n",
    "#     video_manager.start()\n",
    "#     scene_manager.detect_scenes(frame_source=video_manager)\n",
    "    \n",
    "#     with open(stats_path, 'w') as f:\n",
    "#         stats_manager.save_to_csv(f, video_manager.get_base_timecode())\n",
    "    \n",
    "#     scene_list = scene_manager.get_scene_list()\n",
    "#     print(f\"Detected {len(scene_list)} scenes in {video}\")\n",
    "    \n",
    "#     # Save scene images and HTML summary\n",
    "#     save_images(scene_list, video_manager, num_images=1, image_name_template='$SCENE_NUMBER', output_dir=scenes_dir)\n",
    "#     if scene_list:\n",
    "#         try:\n",
    "#             write_scene_list_html(os.path.join(os.getcwd(), \"result.html\"), scene_list)\n",
    "#         except Exception as e:\n",
    "#             print(\"Warning: Could not write HTML summary:\", e)\n",
    "    \n",
    "#     scenes = []\n",
    "#     for scene in scene_list:\n",
    "#         start, end = scene\n",
    "#         scenes.append(float(start.get_seconds()))\n",
    "#         scenes.append(float(end.get_seconds()))\n",
    "    \n",
    "#     return scenes\n",
    "\n",
    "# # ------------------------------\n",
    "# # Main feature extraction routine\n",
    "# # ------------------------------\n",
    "# def extract_feats_pretrained_cnn():\n",
    "#     \"\"\"\n",
    "#     Iterates over all videos in the video directory, detects scenes,\n",
    "#     extracts features for each scene, and saves them as .npy files.\n",
    "#     Also writes out a JSON mapping file of video IDs to feature file names.\n",
    "#     \"\"\"\n",
    "#     model = model_cnn_load()\n",
    "#     video_list = os.listdir(video_dir)\n",
    "    \n",
    "#     # For testing purposes, you can limit the number of videos processed.\n",
    "#     video_list = video_list[:4]\n",
    "    \n",
    "#     feature_mapping = {}  # to map video IDs to feature file names\n",
    "    \n",
    "#     for video in video_list:\n",
    "#         video_id = os.path.splitext(video)[0]\n",
    "#         print(f\"Processing video: {video}\")\n",
    "        \n",
    "#         # Detect scenes using scenedetect\n",
    "#         scenes = proposal_module(video, video_dir)\n",
    "#         if not scenes or len(scenes) < 2:\n",
    "#             print(f\"Not enough scene boundaries detected for {video}. Skipping...\")\n",
    "#             continue\n",
    "        \n",
    "#         feature_mapping[video_id] = []\n",
    "#         count = 0\n",
    "#         # Process each detected scene (start and end timestamps)\n",
    "#         for i in range(0, len(scenes), 2):\n",
    "#             count += 1\n",
    "#             if count == 1:\n",
    "#                 outfile = os.path.join(feat_dir, f\"{video_id}.npy\")\n",
    "#             else:\n",
    "#                 outfile = os.path.join(feat_dir, f\"{video_id}_{count}.npy\")\n",
    "#             print(f\"Extracting features for scene {count} of {video}\")\n",
    "            \n",
    "#             feats = extract_features(video, model, scenes[i], scenes[i+1], video_dir, temp_dir)\n",
    "#             if feats is not None:\n",
    "#                 np.save(outfile, feats)\n",
    "#                 print(f\"Saved features to {outfile}\")\n",
    "#                 feature_mapping[video_id].append(outfile)\n",
    "#             else:\n",
    "#                 print(f\"Feature extraction failed for scene {count} of {video}\")\n",
    "    \n",
    "#     # Write the feature mapping to a JSON file\n",
    "#     mapping_file = os.path.join(feat_dir, \"feat_mapping.json\")\n",
    "#     with open(mapping_file, \"w\") as f:\n",
    "#         json.dump(feature_mapping, f, indent=2)\n",
    "#     print(f\"Feature mapping saved to {mapping_file}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     extract_feats_pretrained_cnn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 299\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest feature mapping saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_mapping_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 299\u001b[0m     \u001b[43mextract_feats_with_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 217\u001b[0m, in \u001b[0;36mextract_feats_with_split\u001b[1;34m()\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Copy videos to separate directories\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m train_videos:\n\u001b[1;32m--> 217\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideos_all_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideos_train_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video \u001b[38;5;129;01min\u001b[39;00m test_videos:\n\u001b[0;32m    219\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopy(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(videos_all_dir, video), os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(videos_test_dir, video))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:423\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    422\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 423\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:262\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    263\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[0;32m    264\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[0;32m    265\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# Set up directories based on current working directory\n",
    "# ------------------------------\n",
    "base_dir = os.path.join(os.getcwd(), \"features\")  # Base directory for all features and videos\n",
    "\n",
    "# Original videos are assumed to be stored in \"videos_all\"\n",
    "videos_all_dir = os.path.join(base_dir, \"videos\")\n",
    "# Create separate directories for training and test videos\n",
    "videos_train_dir = os.path.join(base_dir, \"videos_train\")\n",
    "videos_test_dir  = os.path.join(base_dir, \"videos_test\")\n",
    "\n",
    "# Directories for saving extracted features\n",
    "feat_train_dir = os.path.join(base_dir, \"feat_train\")\n",
    "feat_test_dir  = os.path.join(base_dir, \"feat_test\")\n",
    "\n",
    "# Other directories\n",
    "temp_dir = os.path.join(base_dir, \"temporary_images\")  # Temporary folder for frame extraction\n",
    "scenes_dir = os.path.join(base_dir, \"scenes\")            # Directory to save scene images\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "os.makedirs(videos_all_dir, exist_ok=True)\n",
    "os.makedirs(videos_train_dir, exist_ok=True)\n",
    "os.makedirs(videos_test_dir, exist_ok=True)\n",
    "os.makedirs(feat_train_dir, exist_ok=True)\n",
    "os.makedirs(feat_test_dir, exist_ok=True)\n",
    "os.makedirs(scenes_dir, exist_ok=True)\n",
    "# temp_dir will be created/deleted on the fly\n",
    "\n",
    "# ------------------------------\n",
    "# Set device (CPU if no CUDA available)\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ------------------------------\n",
    "# Define the PyTorch Model Wrapper for EfficientNetB7\n",
    "# ------------------------------\n",
    "class EfficientNetB7_Features(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps torchvision's EfficientNetB7 to output features from the penultimate layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_model):\n",
    "        super(EfficientNetB7_Features, self).__init__()\n",
    "        self.features = base_model.features\n",
    "        self.avgpool = base_model.avgpool\n",
    "        self.dropout = base_model.classifier[0]  # keep the dropout output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def model_cnn_load():\n",
    "    \"\"\"\n",
    "    Loads a pretrained EfficientNetB7 model from torchvision,\n",
    "    wraps it to output feature vectors, and moves it to the appropriate device.\n",
    "    \"\"\"\n",
    "    base_model = models.efficientnet_b7(pretrained=True)\n",
    "    model_final = EfficientNetB7_Features(base_model)\n",
    "    model_final.to(device)\n",
    "    print(\"Model loaded:\")\n",
    "    print(model_final)\n",
    "    return model_final\n",
    "\n",
    "# ------------------------------\n",
    "# Define image transformation pipeline\n",
    "# ------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((600, 600)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"\n",
    "    Loads an image using PIL and applies the transformation.\n",
    "    \"\"\"\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    return transform(img)\n",
    "\n",
    "# ------------------------------\n",
    "# Frame extraction from video segments\n",
    "# ------------------------------\n",
    "def video_to_frames(video, startT, stopT, video_directory, tmp_dir):\n",
    "    \"\"\"\n",
    "    Extracts frames from a video between startT and stopT (in seconds).\n",
    "    Returns a list of file paths to the extracted frames.\n",
    "    \"\"\"\n",
    "    startT_ms = startT * 1000\n",
    "    stopT_ms = stopT * 1000\n",
    "\n",
    "    if os.path.exists(tmp_dir):\n",
    "        shutil.rmtree(tmp_dir)\n",
    "    os.makedirs(tmp_dir)\n",
    "    \n",
    "    video_path = os.path.join(video_directory, video)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    count = 0\n",
    "    image_list = []\n",
    "    success = True\n",
    "    \n",
    "    # Skip frames until reaching startT\n",
    "    while success and cap.get(cv2.CAP_PROP_POS_MSEC) < startT_ms:\n",
    "        success, _ = cap.read()\n",
    "    \n",
    "    # Extract frames until stopT is reached\n",
    "    while success and cap.get(cv2.CAP_PROP_POS_MSEC) <= stopT_ms:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(tmp_dir, f'frame{count}.jpg')\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        image_list.append(frame_path)\n",
    "        count += 1\n",
    "        \n",
    "    cap.release()\n",
    "    print(f\"Extracted {len(image_list)} frames from {video}\")\n",
    "    return image_list\n",
    "\n",
    "# ------------------------------\n",
    "# Feature extraction for a video scene\n",
    "# ------------------------------\n",
    "def extract_features(video, model, startT, stopT, video_directory, tmp_dir):\n",
    "    \"\"\"\n",
    "    Extracts features for a video scene defined by startT and stopT.\n",
    "    Uniformly samples 20 frames, processes them, and passes them through the CNN model.\n",
    "    Returns a NumPy array containing the extracted features.\n",
    "    \"\"\"\n",
    "    image_list = video_to_frames(video, startT, stopT, video_directory, tmp_dir)\n",
    "    if len(image_list) == 0:\n",
    "        print(\"No frames extracted!\")\n",
    "        return None\n",
    "    samples = np.round(np.linspace(0, len(image_list) - 1, 20)).astype(int)\n",
    "    sampled_images = [image_list[i] for i in samples]\n",
    "    \n",
    "    images = [load_image(p) for p in sampled_images]\n",
    "    images = torch.stack(images).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        features = model(images)\n",
    "    features = features.cpu().numpy()\n",
    "    \n",
    "    # Clean up temporary directory\n",
    "    shutil.rmtree(tmp_dir)\n",
    "    return features\n",
    "\n",
    "# ------------------------------\n",
    "# Scene detection using scenedetect\n",
    "# ------------------------------\n",
    "def proposal_module(video, video_directory):\n",
    "    \"\"\"\n",
    "    Detects scenes in a video using scenedetect.\n",
    "    Saves representative scene images in the 'scenes' directory and an HTML summary.\n",
    "    Returns a list of timestamps (in seconds); for each scene, two values (start and end) are appended.\n",
    "    \"\"\"\n",
    "    # Assume VideoManager, StatsManager, SceneManager, ContentDetector, save_images, write_scene_list_html are imported\n",
    "    video_path = os.path.join(video_directory, video)\n",
    "    stats_path = os.path.join(os.getcwd(), \"result.csv\")\n",
    "    \n",
    "    video_manager = VideoManager([video_path])\n",
    "    stats_manager = StatsManager()\n",
    "    scene_manager = SceneManager(stats_manager)\n",
    "    \n",
    "    scene_manager.add_detector(ContentDetector(threshold=30))\n",
    "    video_manager.set_downscale_factor()\n",
    "    \n",
    "    video_manager.start()\n",
    "    scene_manager.detect_scenes(frame_source=video_manager)\n",
    "    \n",
    "    with open(stats_path, 'w') as f:\n",
    "        stats_manager.save_to_csv(f, video_manager.get_base_timecode())\n",
    "    \n",
    "    scene_list = scene_manager.get_scene_list()\n",
    "    print(f\"Detected {len(scene_list)} scenes in {video}\")\n",
    "    \n",
    "    # Save scene images and HTML summary\n",
    "    save_images(scene_list, video_manager, num_images=1, image_name_template='$SCENE_NUMBER', output_dir=scenes_dir)\n",
    "    if scene_list:\n",
    "        try:\n",
    "            write_scene_list_html(os.path.join(os.getcwd(), \"result.html\"), scene_list)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: Could not write HTML summary:\", e)\n",
    "    \n",
    "    scenes = []\n",
    "    for scene in scene_list:\n",
    "        start, end = scene\n",
    "        scenes.append(float(start.get_seconds()))\n",
    "        scenes.append(float(end.get_seconds()))\n",
    "    \n",
    "    return scenes\n",
    "\n",
    "# ------------------------------\n",
    "# Main routine: Train-Test Split and Feature Extraction\n",
    "# ------------------------------\n",
    "def extract_feats_with_split():\n",
    "    \"\"\"\n",
    "    Splits videos from the 'videos_all' folder into training and testing sets,\n",
    "    copies them to respective folders, extracts features for each video scene,\n",
    "    and writes out mapping files and text files listing the videos.\n",
    "    \"\"\"\n",
    "    # Define the train-test split ratio\n",
    "    train_ratio = 0.85\n",
    "\n",
    "    # Get list of all videos from videos_all_dir\n",
    "    all_videos = [f for f in os.listdir(videos_all_dir) if os.path.isfile(os.path.join(videos_all_dir, f))]\n",
    "    random.shuffle(all_videos)\n",
    "    split_index = int(len(all_videos) * train_ratio)\n",
    "    train_videos = all_videos[:split_index]\n",
    "    test_videos = all_videos[split_index:]\n",
    "    \n",
    "    # Copy videos to separate directories\n",
    "    for video in train_videos:\n",
    "        shutil.copy(os.path.join(videos_all_dir, video), os.path.join(videos_train_dir, video))\n",
    "    for video in test_videos:\n",
    "        shutil.copy(os.path.join(videos_all_dir, video), os.path.join(videos_test_dir, video))\n",
    "    \n",
    "    # Write out lists of video IDs\n",
    "    with open(os.path.join(base_dir, \"train_videos.txt\"), \"w\") as f:\n",
    "        for video in train_videos:\n",
    "            f.write(os.path.splitext(video)[0] + \"\\n\")\n",
    "    with open(os.path.join(base_dir, \"test_videos.txt\"), \"w\") as f:\n",
    "        for video in test_videos:\n",
    "            f.write(os.path.splitext(video)[0] + \"\\n\")\n",
    "    \n",
    "    # Initialize model\n",
    "    model = model_cnn_load()\n",
    "    \n",
    "    # Process training videos\n",
    "    train_mapping = {}\n",
    "    print(\"Extracting features for training videos...\")\n",
    "    for video in train_videos:\n",
    "        video_id = os.path.splitext(video)[0]\n",
    "        print(f\"Processing training video: {video}\")\n",
    "        scenes = proposal_module(video, videos_train_dir)\n",
    "        if not scenes or len(scenes) < 2:\n",
    "            print(f\"Not enough scene boundaries detected for {video}. Skipping...\")\n",
    "            continue\n",
    "        train_mapping[video_id] = []\n",
    "        count = 0\n",
    "        for i in range(0, len(scenes), 2):\n",
    "            count += 1\n",
    "            if count == 1:\n",
    "                outfile = os.path.join(feat_train_dir, f\"{video_id}.npy\")\n",
    "            else:\n",
    "                outfile = os.path.join(feat_train_dir, f\"{video_id}_{count}.npy\")\n",
    "            print(f\"Extracting features for scene {count} of {video}\")\n",
    "            feats = extract_features(video, model, scenes[i], scenes[i+1], videos_train_dir, temp_dir)\n",
    "            if feats is not None:\n",
    "                np.save(outfile, feats)\n",
    "                print(f\"Saved features to {outfile}\")\n",
    "                train_mapping[video_id].append(outfile)\n",
    "            else:\n",
    "                print(f\"Feature extraction failed for scene {count} of {video}\")\n",
    "    \n",
    "    # Save train mapping JSON\n",
    "    train_mapping_file = os.path.join(feat_train_dir, \"feat_mapping_train.json\")\n",
    "    with open(train_mapping_file, \"w\") as f:\n",
    "        json.dump(train_mapping, f, indent=2)\n",
    "    print(f\"Training feature mapping saved to {train_mapping_file}\")\n",
    "    \n",
    "    # Process test videos\n",
    "    test_mapping = {}\n",
    "    print(\"Extracting features for test videos...\")\n",
    "    for video in test_videos:\n",
    "        video_id = os.path.splitext(video)[0]\n",
    "        print(f\"Processing test video: {video}\")\n",
    "        scenes = proposal_module(video, videos_test_dir)\n",
    "        if not scenes or len(scenes) < 2:\n",
    "            print(f\"Not enough scene boundaries detected for {video}. Skipping...\")\n",
    "            continue\n",
    "        test_mapping[video_id] = []\n",
    "        count = 0\n",
    "        for i in range(0, len(scenes), 2):\n",
    "            count += 1\n",
    "            if count == 1:\n",
    "                outfile = os.path.join(feat_test_dir, f\"{video_id}.npy\")\n",
    "            else:\n",
    "                outfile = os.path.join(feat_test_dir, f\"{video_id}_{count}.npy\")\n",
    "            print(f\"Extracting features for scene {count} of {video}\")\n",
    "            feats = extract_features(video, model, scenes[i], scenes[i+1], videos_test_dir, temp_dir)\n",
    "            if feats is not None:\n",
    "                np.save(outfile, feats)\n",
    "                print(f\"Saved features to {outfile}\")\n",
    "                test_mapping[video_id].append(outfile)\n",
    "            else:\n",
    "                print(f\"Feature extraction failed for scene {count} of {video}\")\n",
    "    \n",
    "    # Save test mapping JSON\n",
    "    test_mapping_file = os.path.join(feat_test_dir, \"feat_mapping_test.json\")\n",
    "    with open(test_mapping_file, \"w\") as f:\n",
    "        json.dump(test_mapping, f, indent=2)\n",
    "    print(f\"Test feature mapping saved to {test_mapping_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_feats_with_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "extractFeaturesEfficientNetB7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
